{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Disaster-prediction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPtI2vpMwAXEayLjp7hPnVY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanyarw/disaster-prediction/blob/main/Disaster_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKLQ_L8t6XAn"
      },
      "source": [
        "Mount content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N2LyNUxdTVz",
        "outputId": "cc528d51-d8b9-4408-a8a5-f4c38e23092b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI0aVMK6dVZ8"
      },
      "source": [
        "import os\n",
        "os.chdir(\"drive/My Drive/DV: Disaster Prediction\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRgS_pJp_vNK"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veL0L259_KsT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn import preprocessing\n",
        "from sklearn import utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKT5m3DGi0xU"
      },
      "source": [
        "# **GLOBAL LANDSLIDES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcnKL76A6au4"
      },
      "source": [
        "Read Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHqRbo0cAF0V"
      },
      "source": [
        "landslide_df = pd.read_csv('Datasets/NASA_Global_Landslide_Catalog.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6OC0bGQ_n04"
      },
      "source": [
        "Drop unwanted features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82_1r43YAw_C"
      },
      "source": [
        "landslide_df = landslide_df.drop(['source_name', 'source_link','event_id', 'event_date','event_time',\n",
        "                        'event_title', 'event_description', 'location_description','storm_name','photo_link',\n",
        "                        'notes', 'event_import_source','event_import_id','country_code','submitted_date', \n",
        "                        'created_date', 'last_edited_date','admin_division_name','gazeteer_closest_point', 'gazeteer_distance','injury_count'], axis = 1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhlDVNSGK43y"
      },
      "source": [
        "Drop unknown categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKzCj1-__rab"
      },
      "source": [
        "to_remove = landslide_df[ (landslide_df['landslide_category'] == 'unknown') ].index\n",
        "landslide_df = landslide_df.drop(to_remove)\n",
        "to_remove = landslide_df[(landslide_df['location_accuracy'] == 'unknown')].index\n",
        "landslide_df = landslide_df.drop(to_remove)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XYX8lxpK-r1"
      },
      "source": [
        "Replace or drop unknown/NaN values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWQrV63TnRAI"
      },
      "source": [
        "landslide_df = landslide_df.dropna(subset=['location_accuracy', 'landslide_category','landslide_trigger','landslide_size','landslide_setting','country_name'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlu46dag6oYC"
      },
      "source": [
        "Determine feature and target vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO0fChvNFzDm"
      },
      "source": [
        "X_features = list(landslide_df.columns)\n",
        "X_features.remove('fatality_count')\n",
        "y = landslide_df['fatality_count']\n",
        "y = y.fillna(y.median()) # deal with na"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Tu_yOsbjOXa"
      },
      "source": [
        "One hot encoding of categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF__vdWoFbaC"
      },
      "source": [
        "encode_df = pd.get_dummies(landslide_df[X_features])\n",
        "X = encode_df"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r-QRHiFcmCQ"
      },
      "source": [
        "Train and test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjApf6KIbkwu"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0kKvdS_KjTX"
      },
      "source": [
        "Perform regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8DjynSrGtQY"
      },
      "source": [
        "clf = RandomForestRegressor(n_estimators=150, max_depth = None, criterion='mse')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j45TfOEhKs1C"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YbNfMNcv58S",
        "outputId": "4bb18eb6-7b00-4b63-e794-6e554dca85c6"
      },
      "source": [
        "mean_absolute_error(y_test, y_pred)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.824497099008048"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye9Tzil7ivy9"
      },
      "source": [
        "# **INDIAN RAINFALL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0L1gZHKRi1K"
      },
      "source": [
        "Read dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFWkpXJCiwCN"
      },
      "source": [
        "rainfall_df = pd.read_csv('Datasets/rainfall_india_1901-2017.csv')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2GpOmlRKXFV"
      },
      "source": [
        "Deal with NaN values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYFJSO3e2tjf"
      },
      "source": [
        "rainfall_df.fillna(value = 0, inplace = True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfklpMMlKaq5"
      },
      "source": [
        "Split train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhjl0nle205h"
      },
      "source": [
        "div_data = np.asarray(rainfall_df[['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC']])\n",
        "\n",
        "X = None; y = None\n",
        "for i in range(div_data.shape[1]-3):\n",
        "    if X is None: \n",
        "        X = div_data[:, i:i+3] # Three consecutive months\n",
        "        y = div_data[:, i+3] # Next (fourth) month\n",
        "    else:\n",
        "        X = np.concatenate((X, div_data[:, i:i+3]), axis=0) # Three consecutive months\n",
        "        y = np.concatenate((y, div_data[:, i+3]), axis=0) # Next (fourth) month\n",
        "        \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjxYKh0MKfTF"
      },
      "source": [
        "Perform Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Itcpmgy3G-3"
      },
      "source": [
        "rf = RandomForestRegressor(n_estimators = 200, max_depth=10)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMEcew8E5WkM"
      },
      "source": [
        "Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBPCoU2vyCai",
        "outputId": "07c74fca-b714-4ca3-ba48-912777c98153"
      },
      "source": [
        "mean_absolute_error(y_test, y_pred)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83.56942289876253"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpHWxBhIZn3O"
      },
      "source": [
        "# **USA EARTHQUAKES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcrBliN3jloW"
      },
      "source": [
        "earthquake_df = pd.read_csv('Datasets/earthquake-all-month.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB38zLj01AH-"
      },
      "source": [
        "import re\n",
        "earthquake_df['short place']=[re.findall(r'\\w+',i)[-1] for i in earthquake_df['place']]\n",
        "earthquake_df.dropna(subset=['mag'],inplace=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7OhyfqDmx0q"
      },
      "source": [
        "Feature vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiaaUHDjmtSF"
      },
      "source": [
        "features=[i for i in earthquake_df.columns if earthquake_df[i].isna().sum()==0] # features include only place, type and source of an earthquake\n",
        "\n",
        "for i in ['mag','place','time','id','updated','net','magType','depth']:\n",
        "    features.remove(i)\n",
        "    \n",
        "X=earthquake_df[features]\n",
        "y=earthquake_df[['mag','depth', 'depthError']] # we try to predict magnitude, depth as well as depthError  "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d15PCqSmoGDZ"
      },
      "source": [
        "Segregate categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M99hSzraoCoK"
      },
      "source": [
        "categorical = []\n",
        "for i in features:\n",
        "    if earthquake_df[i].dtype==\"object\":\n",
        "        categorical.append(i)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEHfF_4boR8O"
      },
      "source": [
        "Encode the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "299HyBl2oTvl",
        "outputId": "5cd725d6-7e51-4acd-c016-c7600665cc1a"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "for i in categorical:\n",
        "    X[i]=le.fit_transform(X[i])\n",
        "for i in [i for i in y.columns if y[i].dtype=='object']:\n",
        "    y[i]=le.fit_transform(y[i])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq978z08oaRw"
      },
      "source": [
        "Train and test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrYo3-J9ocZp"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.10)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1TwkJqPogm9"
      },
      "source": [
        "Random forest regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2GWZNOzoikL",
        "outputId": "3215e436-6098-49ef-c0f0-87eff5f317fe"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "clf = RandomForestRegressor(n_estimators=100, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
              "                      random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO4HzRo2pnzn"
      },
      "source": [
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0tBsPkQopI2"
      },
      "source": [
        "Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKuSmjVMpdYO",
        "outputId": "813b47ea-3558-461f-a255-a1c50d93a669"
      },
      "source": [
        "mean_absolute_error(y_test, y_pred)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.320238053912668"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}